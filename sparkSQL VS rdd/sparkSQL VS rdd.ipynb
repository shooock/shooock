{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents<a class=\"anchor\" id=\"table\"></a>\n",
    "\n",
    "* [1 Working with RDD](#1)\n",
    "* [1.1 Data Preparation and Loading](#1.1)\n",
    "* [1.1.1 Creating SparkSession & SparkContext](#OneOneOne)\n",
    "* [1.1.2 Read CSV files, Preprocessing, and final(formatted data) RDD for each file](#OneOneTwo)\n",
    "* [1.1.2.1 Flights RDD](#1.1.2.1)\n",
    "* [1.1.2.2 Airports RDD](#1.1.2.2)\n",
    "* [1.1.3 Show RDD number of columns, and number of records](#1.1.3)\n",
    "* [1.2 Dataset flights partitioning](#1.2)\n",
    "* [1.2.1 Obtain the maximum arrival time ](#1.2.1)\n",
    "* [1.2.2 Obtain the maximum minimum time ](#1.2.2)\n",
    "* [1.2.3 Define hash partitioning](#1.2.3)\n",
    "* [1.2.4 Display the records in each partition](#1.2.4)\n",
    "* [1.3 Query RDD](#1.3)\n",
    "* [1.3.1 Collect a total number of flights for each month for all flights](#1.3.1)\n",
    "* [1.3.2 Collect the average delay for each month for all flights](#1.3.2)\n",
    "* [2 Working with DataFrames](#2)\n",
    "* [2.1 Data Preparation and Loading](#2.1)\n",
    "* [2.1.1 Define DataFrames](#2.1.1)\n",
    "* [2.1.2 Display the Scheme of DataFrames](#2.1.2)\n",
    "* [2.1.3 Transform date-time and location column](#2.1.3)\n",
    "* [2.2.1 January Flights Events with ANC airport](#2.2.1)\n",
    "* [2.2.2 Average Arrival Delay From Origin to Destination](#2.2.2)\n",
    "* [2.2.3 Join Query with Airports DataFrame](#2.2.3)\n",
    "* [2.3 Analysis](#2.3.1)\n",
    "* [2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights](#2.3.1)\n",
    "* [2.3.2 Display mean arrival delay each month](#2.3.2)\n",
    "* [2.3.3 Relationship between mean departure delay and mean arrival delay](#2.3.3)\n",
    "* [3 RDDs vs DataFrame vs Spark SQL](#3)\n",
    "* [3.1 RDD Operation](#3.1)\n",
    "* [3.2 DataFrame Operation](#3.1)\n",
    "* [3.3 Spark SQL Operation](#3.1)\n",
    "* [3.4 Discussion](#3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 Working with RDD<a class=\"anchor\" id=\"1\"></a>\n",
    "## 1.1 Data Preparation and Loading<a class=\"anchor\" id=\"1.1\"></a>\n",
    "### 1.1.1 Create SparkSession and SparkContext<a class=\"anchor\" id=\"OneOneOne\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkConf class into program\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# local[*]: run Spark in local mode with as many working processors as logical cores on your machine\n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as \"local[k]\".\n",
    "master = \"local[*]\"\n",
    "# The `appName` field is a name to be shown on the Spark cluster UI page\n",
    "app_name = \"31395996_Assignment 1\"\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "\n",
    "# Import SparkSession classes \n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "#TODO : Initialize Spark Session and create a SparkContext Object\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "sc= spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Import CSV files and Make RDD for each file<a class=\"anchor\" id=\"OneOneTwo\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Flights RDD <a class=\"anchor\" id=\"1.1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: There are airplanes cancled or diverted. We can't change a ' ' string into float format. So, I just drop them which airplane are cancled or diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(YEAR=2015, MONTH=6, DAY=26, DAY_OF_WEEK=5, AIRLINE='EV', FLIGHT_NUMBER=4951, TAIL_NUMBER='N707EV', ORIFIN_AIRPORT='BHM', DESTINATION_AIRPORT='LGA', SHEDULED_DEPARTURE='630', DEPARTURE_TIME='629', DEPARTURE_DELAY=-1.0, TAXI_OUR=13.0, WHEELS_OFF='642', SCHEDULED_TIME='155', ELAPSED_TIME=141.0, AIR_TIME=113.0, DISTANCE=866.0, WHEELS_ON='935', TAXI_IN=15.0, SHEDULED_ARRIVAL='1005', ARRIVAL_TIME='950', ARRIVAL_DELAY=-15.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY=''),\n",
       " Row(YEAR=2015, MONTH=12, DAY=19, DAY_OF_WEEK=6, AIRLINE='WN', FLIGHT_NUMBER=3589, TAIL_NUMBER='N764SW', ORIFIN_AIRPORT='MKE', DESTINATION_AIRPORT='DCA', SHEDULED_DEPARTURE='1630', DEPARTURE_TIME='1627', DEPARTURE_DELAY=-3.0, TAXI_OUR=13.0, WHEELS_OFF='1640', SCHEDULED_TIME='115', ELAPSED_TIME=96.0, AIR_TIME=79.0, DISTANCE=634.0, WHEELS_ON='1859', TAXI_IN=4.0, SHEDULED_ARRIVAL='1925', ARRIVAL_TIME='1903', ARRIVAL_DELAY=-22.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY=''),\n",
       " Row(YEAR=2015, MONTH=1, DAY=10, DAY_OF_WEEK=6, AIRLINE='WN', FLIGHT_NUMBER=3370, TAIL_NUMBER='N720WN', ORIFIN_AIRPORT='SNA', DESTINATION_AIRPORT='OAK', SHEDULED_DEPARTURE='1055', DEPARTURE_TIME='1054', DEPARTURE_DELAY=-1.0, TAXI_OUR=11.0, WHEELS_OFF='1105', SCHEDULED_TIME='85', ELAPSED_TIME=80.0, AIR_TIME=63.0, DISTANCE=371.0, WHEELS_ON='1208', TAXI_IN=6.0, SHEDULED_ARRIVAL='1220', ARRIVAL_TIME='1214', ARRIVAL_DELAY=-6.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY=''),\n",
       " Row(YEAR=2015, MONTH=11, DAY=1, DAY_OF_WEEK=7, AIRLINE='WN', FLIGHT_NUMBER=2081, TAIL_NUMBER='N461WN', ORIFIN_AIRPORT='PDX', DESTINATION_AIRPORT='LAS', SHEDULED_DEPARTURE='1345', DEPARTURE_TIME='1346', DEPARTURE_DELAY=1.0, TAXI_OUR=9.0, WHEELS_OFF='1355', SCHEDULED_TIME='120', ELAPSED_TIME=115.0, AIR_TIME=97.0, DISTANCE=763.0, WHEELS_ON='1532', TAXI_IN=9.0, SHEDULED_ARRIVAL='1545', ARRIVAL_TIME='1541', ARRIVAL_DELAY=-4.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY=''),\n",
       " Row(YEAR=2015, MONTH=6, DAY=11, DAY_OF_WEEK=4, AIRLINE='WN', FLIGHT_NUMBER=836, TAIL_NUMBER='N8628A', ORIFIN_AIRPORT='BNA', DESTINATION_AIRPORT='BOS', SHEDULED_DEPARTURE='1635', DEPARTURE_TIME='1627', DEPARTURE_DELAY=-8.0, TAXI_OUR=12.0, WHEELS_OFF='1639', SCHEDULED_TIME='150', ELAPSED_TIME=149.0, AIR_TIME=127.0, DISTANCE=942.0, WHEELS_ON='1946', TAXI_IN=10.0, SHEDULED_ARRIVAL='2005', ARRIVAL_TIME='1956', ARRIVAL_DELAY=-9.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY='')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_flights_rdd():\n",
    "    raw_flights_rdd = sc.textFile('flight-delays/flight*.csv')\n",
    "    header=raw_flights_rdd.first()\n",
    "    flights_rdd=raw_flights_rdd.filter(lambda x:x!=header)\\\n",
    "                               .map(lambda x:x.split(','))\\\n",
    "                               .filter(lambda x:x[23]!='1' and x[24]!='1')\\\n",
    "                               .map(lambda x:Row(YEAR=int(x[0]),\n",
    "                                MONTH=int(x[1]),DAY=int(x[2]),DAY_OF_WEEK=int(x[3]),\n",
    "                                AIRLINE=x[4],FLIGHT_NUMBER=int(x[5]),TAIL_NUMBER=x[6],\n",
    "                                ORIFIN_AIRPORT=x[7],DESTINATION_AIRPORT=x[8],\n",
    "                                SHEDULED_DEPARTURE=x[9],DEPARTURE_TIME=x[10],\n",
    "                                DEPARTURE_DELAY=float(x[11]),TAXI_OUR=float(x[12]),\n",
    "                                WHEELS_OFF=x[13],SCHEDULED_TIME=x[14],ELAPSED_TIME=float(x[15]),\n",
    "                                AIR_TIME=float(x[16]),DISTANCE=float(x[17]),\n",
    "                                WHEELS_ON=x[18],TAXI_IN=float(x[19]),\n",
    "                                SHEDULED_ARRIVAL=x[20],ARRIVAL_TIME=x[21],\n",
    "                                ARRIVAL_DELAY=float(x[22]),DIVERTED=x[23],\n",
    "                                CANCELLED=x[24],CANCELLATION_REASON=x[25],\n",
    "                                AIR_SYSTEM_DELAY=x[26],SECURITY_DELAY=x[27],\n",
    "                                AIRLINE_DELAY=x[28],LATE_AIRCRAFT_DELAY=x[29],\n",
    "                                WEATHER_DELAY=x[30]))\n",
    "    return flights_rdd\n",
    "                                \n",
    "flights_rdd=load_flights_rdd()   \n",
    "flights_rdd.take(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.2 Airports RDD <a class=\"anchor\" id=\"1.1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TATA_CODE='ABE', AIRPORT='Lehigh Valley International Airport', CITY='Allentown', STATE='PA', COUNTRY='USA', LATITUDE='40.65236', LONGITUDE='-75.44040'),\n",
       " Row(TATA_CODE='ABI', AIRPORT='Abilene Regional Airport', CITY='Abilene', STATE='TX', COUNTRY='USA', LATITUDE='32.41132', LONGITUDE='-99.68190'),\n",
       " Row(TATA_CODE='ABQ', AIRPORT='Albuquerque International Sunport', CITY='Albuquerque', STATE='NM', COUNTRY='USA', LATITUDE='35.04022', LONGITUDE='-106.60919'),\n",
       " Row(TATA_CODE='ABR', AIRPORT='Aberdeen Regional Airport', CITY='Aberdeen', STATE='SD', COUNTRY='USA', LATITUDE='45.44906', LONGITUDE='-98.42183'),\n",
       " Row(TATA_CODE='ABY', AIRPORT='Southwest Georgia Regional Airport', CITY='Albany', STATE='GA', COUNTRY='USA', LATITUDE='31.53552', LONGITUDE='-84.19447')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_airports_rdd():\n",
    "    raw_airports_rdd = sc.textFile('flight-delays/airports.csv')\n",
    "    header=raw_airports_rdd.first()\n",
    "    airports_rdd=raw_airports_rdd.filter(lambda x:x!=header)\\\n",
    "                                    .map(lambda x:x.split(','))\\\n",
    "                                    .map(lambda x:Row(TATA_CODE=x[0],\n",
    "                                                     AIRPORT=x[1],\n",
    "                                                     CITY=x[2],\n",
    "                                                     STATE=x[3],\n",
    "                                                     COUNTRY=x[4],\n",
    "                                                     LATITUDE=x[5],\n",
    "                                                     LONGITUDE=x[6]))\n",
    "    \n",
    "    return airports_rdd\n",
    "    \n",
    "airports_rdd=load_airports_rdd()\n",
    "airports_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Show RDD number of columns, and number of records <a class=\"anchor\" id=\"1.1.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airports_rdd's length: 7\n",
      "total number of records:  322\n",
      "total number of partitions: 2\n"
     ]
    }
   ],
   "source": [
    "print('airports_rdd\\'s length:', len(airports_rdd.take(1)[0]))\n",
    "print('total number of records: ', airports_rdd.count())\n",
    "print('total number of partitions:', airports_rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights_rdd's length: 31\n",
      "total number of records:  571729\n",
      "total number of partitions: 20\n"
     ]
    }
   ],
   "source": [
    "print('flights_rdd\\'s length:', len(flights_rdd.take(1)[0]))\n",
    "print('total number of records: ', flights_rdd.count())\n",
    "print('total number of partitions:', flights_rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Flights total number of records are records without cancled airplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Partitioning <a class=\"anchor\" id=\"1.2\"></a>\n",
    "### 1.2.1 Obtain the maximum arrival delay <a class=\"anchor\" id=\"1.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd.max(lambda x: x['ARRIVAL_DELAY'])['ARRIVAL_DELAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Obtain the minimum arrival delay <a class=\"anchor\" id=\"1.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-82.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd.min(lambda x: x['ARRIVAL_DELAY'])['ARRIVAL_DELAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Define hash partitioning function <a class=\"anchor\" id=\"1.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look close to ARRIVAL_DELAY, we will find they have float value,nagetive value,and nonetype. So we need to do a key type check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_type_check(key):\n",
    "    if key == None:\n",
    "        return 0\n",
    "    return int(key)\n",
    "def hash_partition(rdd):\n",
    "    kv=rdd.map(lambda x: (x['ARRIVAL_DELAY'],x))\n",
    "    return  kv.partitionBy(4,key_type_check)\n",
    "flights_rdd_partition = hash_partition(flights_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.0,\n",
       "  Row(YEAR=2015, MONTH=11, DAY=1, DAY_OF_WEEK=7, AIRLINE='WN', FLIGHT_NUMBER=2081, TAIL_NUMBER='N461WN', ORIFIN_AIRPORT='PDX', DESTINATION_AIRPORT='LAS', SHEDULED_DEPARTURE='1345', DEPARTURE_TIME='1346', DEPARTURE_DELAY=1.0, TAXI_OUR=9.0, WHEELS_OFF='1355', SCHEDULED_TIME='120', ELAPSED_TIME=115.0, AIR_TIME=97.0, DISTANCE=763.0, WHEELS_ON='1532', TAXI_IN=9.0, SHEDULED_ARRIVAL='1545', ARRIVAL_TIME='1541', ARRIVAL_DELAY=-4.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='', SECURITY_DELAY='', AIRLINE_DELAY='', LATE_AIRCRAFT_DELAY='', WEATHER_DELAY='')),\n",
       " (40.0,\n",
       "  Row(YEAR=2015, MONTH=4, DAY=8, DAY_OF_WEEK=3, AIRLINE='WN', FLIGHT_NUMBER=1170, TAIL_NUMBER='N408WN', ORIFIN_AIRPORT='MDW', DESTINATION_AIRPORT='PHL', SHEDULED_DEPARTURE='1700', DEPARTURE_TIME='1725', DEPARTURE_DELAY=25.0, TAXI_OUR=32.0, WHEELS_OFF='1757', SCHEDULED_TIME='120', ELAPSED_TIME=135.0, AIR_TIME=94.0, DISTANCE=668.0, WHEELS_ON='2031', TAXI_IN=9.0, SHEDULED_ARRIVAL='2000', ARRIVAL_TIME='2040', ARRIVAL_DELAY=40.0, DIVERTED='0', CANCELLED='0', CANCELLATION_REASON='', AIR_SYSTEM_DELAY='35', SECURITY_DELAY='0', AIRLINE_DELAY='0', LATE_AIRCRAFT_DELAY='5', WEATHER_DELAY='0'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd_partition.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Display the records in each partition <a class=\"anchor\" id=\"1.2.4\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143370\n",
      "143070\n",
      "142335\n",
      "142954\n"
     ]
    }
   ],
   "source": [
    "for p in flights_rdd_partition.glom().collect():\n",
    "    print(len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of partition will influence the records in each partition. According to my test, partition by 4 parts will get a better result. It will have probably equal number of data in each partition. Other number will cause at most one thouand difference from each other.\n",
    "\n",
    "- The reason probably because of the unblance of the data distribution. ARRIVAL_DELAY is from -82 to 1665,but we have much more data to do partition. If ARRIVAL_DELAY have a high frequence on some same number, it probably caused more records in same partition.\n",
    "\n",
    "- When we do int(), actuall, -1 is 1. So we also made some same number here. But it won't influence a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Query RDD  <a class=\"anchor\" id=\"1.3\"></a>\n",
    "### 1.3.1 Collect a total number of flights for each month <a class=\"anchor\" id=\"1.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 45900),\n",
       " (2, 40684),\n",
       " (3, 49580),\n",
       " (4, 48221),\n",
       " (5, 48977),\n",
       " (6, 49158),\n",
       " (7, 51415),\n",
       " (8, 49866),\n",
       " (9, 46459),\n",
       " (10, 48357),\n",
       " (11, 46203),\n",
       " (12, 46909)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd.map(lambda x:(x['MONTH'],1))\\\n",
    "           .reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are flights number without cancled flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Collect the average delay for each month <a class=\"anchor\" id=\"1.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5.804357298474946),\n",
       " (2, 8.123906203913085),\n",
       " (3, 5.011173860427592),\n",
       " (4, 3.173803944339603),\n",
       " (5, 4.7121097658084405),\n",
       " (6, 9.747630090727856),\n",
       " (7, 6.786093552465234),\n",
       " (8, 4.713893233866763),\n",
       " (9, -0.8498676252179341),\n",
       " (10, -0.541989784312509),\n",
       " (11, 0.8313745860658399),\n",
       " (12, 6.15837046195826)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_rdd.map(lambda x:(x['MONTH'],(x['ARRIVAL_DELAY'],1)))\\\n",
    "           .reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\\\n",
    "           .mapValues(lambda x:x[0]/x[1]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working with DataFrame <a class=\"anchor\" id=\"2\"></a>\n",
    "## 2.1. Data Preparation and Loading <a class=\"anchor\" id=\"2.1\"></a>\n",
    "### 2.1.1 Define dataframes and loading scheme<a class=\"anchor\" id=\"2.1.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDf = spark.read.format('csv').option(\"header\",True)\\\n",
    "                                   .option(\"inferSchema\", True)\\\n",
    "                                   .load('flight-delays/flight*.csv')\n",
    "\n",
    "airportsDf = spark.read.format('csv').option(\"header\",True)\\\n",
    "                                   .option(\"inferSchema\", True)\\\n",
    "                                   .load('flight-delays/airports.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Display the schema of the final two dataframes<a class=\"anchor\" id=\"2.1.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDf.printSchema()\n",
    "airportsDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Query Analysis <a class=\"anchor\" id=\"2.2\"></a>\n",
    "### 2.2.1 January flight events with ANC airport <a class=\"anchor\" id=\"2.2.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|MONTH|ORIGIN_AIRPORT|DESTINATION_AIRPORT|DISTANCE|ARRIVAL_DELAY|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "|    1|           ANC|                SEA|    1448|          -13|\n",
      "|    1|           ANC|                SEA|    1448|           -4|\n",
      "|    1|           ANC|                JNU|     571|           17|\n",
      "|    1|           ANC|                CDV|     160|           20|\n",
      "|    1|           ANC|                BET|     399|          -20|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                SEA|    1448|          -11|\n",
      "|    1|           ANC|                ADQ|     253|          -16|\n",
      "|    1|           ANC|                SEA|    1448|           17|\n",
      "|    1|           ANC|                BET|     399|           -9|\n",
      "|    1|           ANC|                SEA|    1448|           15|\n",
      "|    1|           ANC|                FAI|     261|           -6|\n",
      "|    1|           ANC|                JNU|     571|            2|\n",
      "|    1|           ANC|                JNU|     571|           -3|\n",
      "|    1|           ANC|                PDX|    1542|          -21|\n",
      "|    1|           ANC|                SEA|    1448|           -5|\n",
      "|    1|           ANC|                SEA|    1448|          -15|\n",
      "|    1|           ANC|                PDX|    1542|          -13|\n",
      "|    1|           ANC|                SFO|    2018|           20|\n",
      "|    1|           ANC|                FAI|     261|           56|\n",
      "+-----+--------------+-------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "janFlightEventsAncDf = flightsDf.select('MONTH','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DISTANCE','ARRIVAL_DELAY')\\\n",
    "                                .filter(flightsDf.MONTH==1)\\\n",
    "                                .filter(flightsDf.YEAR==2015)\\\n",
    "                                .filter(flightsDf.ORIGIN_AIRPORT=='ANC')\\\n",
    "                                \n",
    "janFlightEventsAncDf.show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Average Arrival Delay From Origin to Destination <a class=\"anchor\" id=\"2.2.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|      AVERAGE_DELAY|\n",
      "+--------------+-------------------+-------------------+\n",
      "|           ANC|                ADK|              -27.0|\n",
      "|           ANC|                HNL|              -20.0|\n",
      "|           ANC|                MSP|             -19.25|\n",
      "|           ANC|                BET| -9.090909090909092|\n",
      "|           ANC|                SEA| -6.490196078431373|\n",
      "|           ANC|                BRW| -4.333333333333333|\n",
      "|           ANC|                OME|               -3.0|\n",
      "|           ANC|                ADQ|-2.6666666666666665|\n",
      "|           ANC|                CDV|                1.0|\n",
      "|           ANC|                OTZ|               1.25|\n",
      "|           ANC|                PHX|                2.0|\n",
      "|           ANC|                DEN| 3.3333333333333335|\n",
      "|           ANC|                PDX|                3.5|\n",
      "|           ANC|                JNU|                5.0|\n",
      "|           ANC|                LAS|                9.0|\n",
      "|           ANC|                SCC| 16.666666666666668|\n",
      "|           ANC|                SFO|               20.0|\n",
      "|           ANC|                FAI|               25.0|\n",
      "+--------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "janFlightEventsAncAvgDf = janFlightEventsAncDf.groupBy(['ORIGIN_AIRPORT','DESTINATION_AIRPORT'])\\\n",
    "                                           .agg(F.avg('ARRIVAL_DELAY').alias('AVERAGE_DELAY'))\\\n",
    "                                           .orderBy('AVERAGE_DELAY')\n",
    "janFlightEventsAncAvgDf.show()                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Join Query with Airports DataFrame <a class=\"anchor\" id=\"2.2.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|      AVERAGE_DELAY|IATA_CODE|             AIRPORT|     CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+--------------+-------------------+-------------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "|           ANC|                BRW| -4.333333333333333|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                ADK|              -27.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OME|               -3.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                JNU|                5.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                LAS|                9.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SCC| 16.666666666666668|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                CDV|                1.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                DEN| 3.3333333333333335|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                OTZ|               1.25|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SFO|               20.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                FAI|               25.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                ADQ|-2.6666666666666665|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                PDX|                3.5|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                PHX|                2.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                HNL|              -20.0|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                SEA| -6.490196078431373|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                MSP|             -19.25|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|           ANC|                BET| -9.090909090909092|      ANC|Ted Stevens Ancho...|Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "+--------------+-------------------+-------------------+---------+--------------------+---------+-----+-------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedSqlDf = janFlightEventsAncAvgDf.join(airportsDf,janFlightEventsAncAvgDf.ORIGIN_AIRPORT== airportsDf.IATA_CODE)\n",
    "\n",
    "joinedSqlDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Analysis <a class=\"anchor\" id=\"2.3\"></a>\n",
    "### 2.3.1 Relationship between day of week with mean arrival delay, total time delay, and count flights <a class=\"anchor\" id=\"2.3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+--------------+---------------+\n",
      "|DAY_OF_WEEK|  MeanArrivalDelay|TotalTimeDelay|NumberOfFlights|\n",
      "+-----------+------------------+--------------+---------------+\n",
      "|          4| 5.684831897201573|        490186|          87683|\n",
      "|          1| 5.883000999381335|        494478|          86317|\n",
      "|          5| 4.715112525093624|        401638|          86253|\n",
      "|          3|3.9745505431431147|        335150|          85607|\n",
      "|          2| 4.391518272706391|        363262|          84449|\n",
      "|          7| 4.299206488272548|        343498|          81422|\n",
      "|          6| 1.813841449342257|        125750|          70453|\n",
      "+-----------+------------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDf.createOrReplaceTempView('sql_flights')\n",
    "delay_vs_no_of_flights = spark.sql('''\n",
    "    SELECT DAY_OF_WEEK,\n",
    "        AVG(ARRIVAL_DELAY) AS MeanArrivalDelay,\n",
    "        SUM(ARRIVAL_DELAY) AS TotalTimeDelay,\n",
    "        COUNT(*) AS NumberOfFlights\n",
    "    FROM sql_flights\n",
    "    WHERE YEAR =2015\n",
    "    GROUP BY DAY_OF_WEEK\n",
    "    ORDER BY COUNT(*) DESC\n",
    "            \n",
    "''')\n",
    "delay_vs_no_of_flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most heavy delay always happened on Thursday and monday. According to dataframe above, we can say the reason probably is because on Thursday and Monday, there are most number of flights. Saturday has lowest arrival delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Display mean arrival delay each month <a class=\"anchor\" id=\"2.3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------+---------------+\n",
      "|MONTH|   MeanArrivalDelay|TotalTimeDelay|NumberOfFlights|\n",
      "+-----+-------------------+--------------+---------------+\n",
      "|    9|-0.8498676252179341|        -39484|          46733|\n",
      "|   10| -0.541989784312509|        -26209|          48680|\n",
      "|   11| 0.8313745860658399|         38412|          46809|\n",
      "|    4|  3.173803944339603|        153044|          48810|\n",
      "|    5| 4.7121097658084405|        230785|          49691|\n",
      "|    8|  4.713893233866763|        235063|          50524|\n",
      "|    3|  5.011173860427592|        248454|          50816|\n",
      "|    1|  5.804357298474946|        266420|          47136|\n",
      "|   12|   6.15837046195826|        288883|          47866|\n",
      "|    7|  6.786093552465234|        348907|          52065|\n",
      "|    2|  8.123906203913085|        330513|          42798|\n",
      "|    6|  9.747630090727856|        479174|          50256|\n",
      "+-----+-------------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_each_month = spark.sql('''\n",
    "SELECT MONTH,\n",
    "    AVG(ARRIVAL_DELAY) AS MeanArrivalDelay,\n",
    "    SUM(ARRIVAL_DELAY) AS TotalTimeDelay,\n",
    "    COUNT(*) AS NumberOfFlights\n",
    "    FROM sql_flights\n",
    "    GROUP BY MONTH\n",
    "    ORDER BY MeanArrivalDelay\n",
    "''')\n",
    "delay_each_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feb and June have highest arrival delay time. But we can't say the reason is that more flights are in Feb and June. The pressure for airport in Sep and Oct is low. Even they also have a lot of flights.\n",
    "- Autumn has lowest delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Relationship between mean departure delay and mean arrival delay <a class=\"anchor\" id=\"2.3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-------------------+\n",
      "|MONTH|     MeanDeptDelay|   MeanArrivalDelay|\n",
      "+-----+------------------+-------------------+\n",
      "|    6|  13.9730063585922|  9.747630090727856|\n",
      "|   12|11.821651454043728|   6.15837046195826|\n",
      "|    7|11.708608758020432|  6.786093552465234|\n",
      "|    2|11.620796080832823|  8.123906203913085|\n",
      "|    8|10.086906141367324|  4.713893233866763|\n",
      "|    1|  9.75401499511029|  5.804357298474946|\n",
      "|    3| 9.718308159530178|  5.011173860427592|\n",
      "|    5| 9.550310180006102| 4.7121097658084405|\n",
      "|    4| 7.737554783759199|  3.173803944339603|\n",
      "|   11| 6.630585898709037| 0.8313745860658399|\n",
      "|   10| 5.243436261558784| -0.541989784312509|\n",
      "|    9| 4.728506981740065|-0.8498676252179341|\n",
      "+-----+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_and_arr_delay = spark.sql('''\n",
    "SELECT MONTH,\n",
    "    AVG(DEPARTURE_DELAY) AS MeanDeptDelay,\n",
    "    AVG(ARRIVAL_DELAY) AS MeanArrivalDelay\n",
    "    FROM sql_flights\n",
    "    GROUP BY MONTH\n",
    "    ORDER BY MeanDeptDelay DESC\n",
    "''')\n",
    "dept_and_arr_delay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More departure delay will cause more arrival delay\n",
    "- June, Dec and July have more delay both on departure and arrival.\n",
    "- Sep,Oct,Nov,we could say autumn has lowest pressure on delay for airports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 RDDs vs DataFrame vs Spark SQL <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "\n",
    "Implement the following queries using RDDs, DataFrames and SparkSQL separately. Log the time taken for each query in each approach using the “%%time” built-in magic command in Jupyter Notebook and discuss the performance difference of these 3 approaches.\n",
    "\n",
    "<strong>Find the MONTH and DAY_OF_WEEK, number of flights, and average delay where TAIL_NUMBER = ‘N407AS’. Note number of flights and average delay should be aggregated separately. The average delay should be grouped by both MONTH and DAYS_OF_WEEK.</strong>\n",
    "\n",
    "## 3.1 RDD Operation<a class=\"anchor\" id=\"3.1\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 ms, sys: 4.27 ms, total: 25.8 ms\n",
      "Wall time: 4.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(MONTH=11, DAY_OF_WEEK=7, NumOfFlights=3, AvgDeptDelay=-5.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=3, NumOfFlights=1, AvgDeptDelay=28.0),\n",
       " Row(MONTH=4, DAY_OF_WEEK=6, NumOfFlights=1, AvgDeptDelay=1.0),\n",
       " Row(MONTH=12, DAY_OF_WEEK=2, NumOfFlights=2, AvgDeptDelay=1.0),\n",
       " Row(MONTH=5, DAY_OF_WEEK=5, NumOfFlights=1, AvgDeptDelay=17.0),\n",
       " Row(MONTH=6, DAY_OF_WEEK=3, NumOfFlights=3, AvgDeptDelay=-5.0),\n",
       " Row(MONTH=7, DAY_OF_WEEK=4, NumOfFlights=2, AvgDeptDelay=-2.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=1, NumOfFlights=2, AvgDeptDelay=-14.0),\n",
       " Row(MONTH=9, DAY_OF_WEEK=2, NumOfFlights=1, AvgDeptDelay=8.0),\n",
       " Row(MONTH=6, DAY_OF_WEEK=2, NumOfFlights=1, AvgDeptDelay=33.0),\n",
       " Row(MONTH=9, DAY_OF_WEEK=3, NumOfFlights=5, AvgDeptDelay=-5.2),\n",
       " Row(MONTH=7, DAY_OF_WEEK=5, NumOfFlights=1, AvgDeptDelay=9.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=7, NumOfFlights=2, AvgDeptDelay=66.5),\n",
       " Row(MONTH=10, DAY_OF_WEEK=1, NumOfFlights=2, AvgDeptDelay=12.5),\n",
       " Row(MONTH=9, DAY_OF_WEEK=4, NumOfFlights=3, AvgDeptDelay=-8.333333333333334),\n",
       " Row(MONTH=2, DAY_OF_WEEK=5, NumOfFlights=1, AvgDeptDelay=-11.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=2, NumOfFlights=2, AvgDeptDelay=-4.0),\n",
       " Row(MONTH=7, DAY_OF_WEEK=7, NumOfFlights=4, AvgDeptDelay=19.75),\n",
       " Row(MONTH=9, DAY_OF_WEEK=1, NumOfFlights=2, AvgDeptDelay=-5.5),\n",
       " Row(MONTH=10, DAY_OF_WEEK=4, NumOfFlights=1, AvgDeptDelay=-11.0),\n",
       " Row(MONTH=1, DAY_OF_WEEK=6, NumOfFlights=3, AvgDeptDelay=8.666666666666666),\n",
       " Row(MONTH=2, DAY_OF_WEEK=3, NumOfFlights=2, AvgDeptDelay=-12.5),\n",
       " Row(MONTH=12, DAY_OF_WEEK=5, NumOfFlights=2, AvgDeptDelay=-4.5),\n",
       " Row(MONTH=2, DAY_OF_WEEK=2, NumOfFlights=2, AvgDeptDelay=-3.5),\n",
       " Row(MONTH=11, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=57.0),\n",
       " Row(MONTH=12, DAY_OF_WEEK=4, NumOfFlights=1, AvgDeptDelay=2.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=2, NumOfFlights=2, AvgDeptDelay=-5.5),\n",
       " Row(MONTH=4, DAY_OF_WEEK=7, NumOfFlights=1, AvgDeptDelay=-8.0),\n",
       " Row(MONTH=12, DAY_OF_WEEK=3, NumOfFlights=2, AvgDeptDelay=1.5),\n",
       " Row(MONTH=1, DAY_OF_WEEK=5, NumOfFlights=2, AvgDeptDelay=-6.0),\n",
       " Row(MONTH=5, DAY_OF_WEEK=2, NumOfFlights=5, AvgDeptDelay=6.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=4, NumOfFlights=1, AvgDeptDelay=1.0),\n",
       " Row(MONTH=4, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=-1.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=5, NumOfFlights=3, AvgDeptDelay=5.666666666666667),\n",
       " Row(MONTH=5, DAY_OF_WEEK=3, NumOfFlights=1, AvgDeptDelay=-6.0),\n",
       " Row(MONTH=10, DAY_OF_WEEK=5, NumOfFlights=3, AvgDeptDelay=-6.333333333333333),\n",
       " Row(MONTH=6, DAY_OF_WEEK=1, NumOfFlights=4, AvgDeptDelay=4.5),\n",
       " Row(MONTH=8, DAY_OF_WEEK=3, NumOfFlights=1, AvgDeptDelay=2.0),\n",
       " Row(MONTH=5, DAY_OF_WEEK=1, NumOfFlights=3, AvgDeptDelay=2.0),\n",
       " Row(MONTH=4, DAY_OF_WEEK=2, NumOfFlights=1, AvgDeptDelay=-2.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=5, NumOfFlights=3, AvgDeptDelay=1.6666666666666667),\n",
       " Row(MONTH=1, DAY_OF_WEEK=2, NumOfFlights=2, AvgDeptDelay=12.5),\n",
       " Row(MONTH=2, DAY_OF_WEEK=7, NumOfFlights=2, AvgDeptDelay=-7.0),\n",
       " Row(MONTH=10, DAY_OF_WEEK=3, NumOfFlights=2, AvgDeptDelay=0.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=4, NumOfFlights=1, AvgDeptDelay=-7.0),\n",
       " Row(MONTH=6, DAY_OF_WEEK=6, NumOfFlights=3, AvgDeptDelay=-2.0),\n",
       " Row(MONTH=7, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=-3.0),\n",
       " Row(MONTH=1, DAY_OF_WEEK=3, NumOfFlights=1, AvgDeptDelay=-7.0),\n",
       " Row(MONTH=2, DAY_OF_WEEK=1, NumOfFlights=2, AvgDeptDelay=-4.0),\n",
       " Row(MONTH=12, DAY_OF_WEEK=7, NumOfFlights=2, AvgDeptDelay=-2.0),\n",
       " Row(MONTH=11, DAY_OF_WEEK=2, NumOfFlights=1, AvgDeptDelay=-9.0),\n",
       " Row(MONTH=8, DAY_OF_WEEK=6, NumOfFlights=2, AvgDeptDelay=-2.0),\n",
       " Row(MONTH=2, DAY_OF_WEEK=4, NumOfFlights=2, AvgDeptDelay=-8.5),\n",
       " Row(MONTH=9, DAY_OF_WEEK=5, NumOfFlights=1, AvgDeptDelay=4.0),\n",
       " Row(MONTH=7, DAY_OF_WEEK=3, NumOfFlights=3, AvgDeptDelay=-0.3333333333333333),\n",
       " Row(MONTH=6, DAY_OF_WEEK=4, NumOfFlights=1, AvgDeptDelay=-6.0),\n",
       " Row(MONTH=1, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=4.0),\n",
       " Row(MONTH=12, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=-5.0),\n",
       " Row(MONTH=5, DAY_OF_WEEK=6, NumOfFlights=2, AvgDeptDelay=0.5),\n",
       " Row(MONTH=11, DAY_OF_WEEK=4, NumOfFlights=2, AvgDeptDelay=-7.5),\n",
       " Row(MONTH=4, DAY_OF_WEEK=4, NumOfFlights=3, AvgDeptDelay=1.6666666666666667),\n",
       " Row(MONTH=5, DAY_OF_WEEK=7, NumOfFlights=3, AvgDeptDelay=4.666666666666667),\n",
       " Row(MONTH=11, DAY_OF_WEEK=5, NumOfFlights=1, AvgDeptDelay=-4.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=1, NumOfFlights=1, AvgDeptDelay=40.0),\n",
       " Row(MONTH=4, DAY_OF_WEEK=3, NumOfFlights=1, AvgDeptDelay=-4.0),\n",
       " Row(MONTH=3, DAY_OF_WEEK=6, NumOfFlights=1, AvgDeptDelay=-1.0)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "flights_rdd.filter(lambda x: x['TAIL_NUMBER'] == 'N407AS')\\\n",
    "          .map(lambda x:((x['MONTH'],x['DAY_OF_WEEK']),(1,x['DEPARTURE_DELAY'])))\\\n",
    "          .reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\\\n",
    "          .map(lambda kv:Row(MONTH=kv[0][0],DAY_OF_WEEK=kv[0][1],NumOfFlights=kv[1][0],AvgDeptDelay=kv[1][1]/kv[1][0]))\\\n",
    "          .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DataFrame Operation<a class=\"anchor\" id=\"3.2\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+------------------+\n",
      "|MONTH|DAY_OF_WEEK|NumofFlights|      AvgDeptDelay|\n",
      "+-----+-----------+------------+------------------+\n",
      "|    6|          1|           4|               4.5|\n",
      "|    3|          1|           1|              40.0|\n",
      "|    7|          4|           2|              -2.0|\n",
      "|    2|          2|           2|              -3.5|\n",
      "|    9|          4|           3|-8.333333333333334|\n",
      "|   12|          7|           2|              -2.0|\n",
      "|    8|          3|           1|               2.0|\n",
      "|    4|          7|           1|              -8.0|\n",
      "|    2|          3|           2|             -12.5|\n",
      "|    7|          1|           1|              -3.0|\n",
      "|   12|          2|           2|               1.0|\n",
      "|    1|          2|           2|              12.5|\n",
      "|   11|          1|           1|              57.0|\n",
      "|    9|          1|           2|              -5.5|\n",
      "|    5|          7|           3| 4.666666666666667|\n",
      "|    5|          6|           2|               0.5|\n",
      "|   12|          1|           1|              -5.0|\n",
      "|   10|          5|           3|-6.333333333333333|\n",
      "|    1|          1|           1|               4.0|\n",
      "|    1|          3|           1|              -7.0|\n",
      "+-----+-----------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.71 ms, sys: 4.86 ms, total: 7.58 ms\n",
      "Wall time: 974 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flightsDf.filter(flightsDf.TAIL_NUMBER == 'N407AS')\\\n",
    "          .groupBy(['MONTH','DAY_OF_WEEK'])\\\n",
    "          .agg(F.count('DEPARTURE_DELAY').alias('NumofFlights'),F.avg('DEPARTURE_DELAY').alias('AvgDeptDelay'))\\\n",
    "          .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Spark SQL OPERATION<a class=\"anchor\" id=\"3.3\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------------+------------------+\n",
      "|MONTH|DAY_OF_WEEK|NumberOfFlights|     MeanDeptDelay|\n",
      "+-----+-----------+---------------+------------------+\n",
      "|   10|          2|           6406|1.5475445730372224|\n",
      "|    6|          1|           8611|15.902471209213052|\n",
      "|    3|          1|           8357|11.533674339300937|\n",
      "|    7|          4|           8824|12.438158497480531|\n",
      "|    2|          2|           6204|  11.3463986599665|\n",
      "|    9|          4|           6623| 8.057355849688118|\n",
      "|   12|          7|           6333|  13.8415681192289|\n",
      "|    8|          3|           6723| 7.469204255956841|\n",
      "|    1|          7|           6043|15.087175188600167|\n",
      "|    2|          3|           6277|  8.78494271685761|\n",
      "|   11|          6|           5426| 6.624717407686511|\n",
      "|    7|          1|           6912|12.489106594531364|\n",
      "|    4|          7|           6284| 5.053471667996807|\n",
      "|   12|          2|           7889|13.592482562645312|\n",
      "|    1|          2|           6087| 8.703690807799443|\n",
      "|   11|          1|           8017| 6.306291598643727|\n",
      "|    9|          1|           6741|3.2761748958953003|\n",
      "|    5|          7|           7713| 11.42139277235558|\n",
      "|    5|          6|           6670| 5.824977348233162|\n",
      "|   12|          1|           6504|14.140392908481074|\n",
      "+-----+-----------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 0 ns, sys: 3.23 ms, total: 3.23 ms\n",
      "Wall time: 968 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flightsDf.createOrReplaceTempView('sql_flights')\n",
    "Spark_op = spark.sql('''\n",
    "    SELECT MONTH, DAY_OF_WEEK,\n",
    "        COUNT(*) AS NumberOfFlights,\n",
    "        AVG(DEPARTURE_DELAY) AS MeanDeptDelay \n",
    "    FROM sql_flights\n",
    "    GROUP BY MONTH,DAY_OF_WEEK\n",
    "\n",
    "            \n",
    "''')\n",
    "Spark_op.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Discussion<a class=\"anchor\" id=\"3.4\"></a>\n",
    "[Back to top](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this task,DataFrame operation and Spark Sql operation are much more quicker than RDD operation(974ms,968ms vs 4.31s)\n",
    "\n",
    "- DataFrame operation and Spark Sql are probably the same.\n",
    "\n",
    "- According to a simple search on the Internet. This is because DataFrame operation and Spark Sql are different from RDD. SPARK SQL and spark dataframe are essentially the same. This is because SPARK SQL is designed for those who want to use spark but are only familiar with sql language. In addition, both DataFrame operation and Spark Sql are optimized by calalyst(https://databricks.com/glossary/catalyst-optimizer). After using calalyst optimization, their processing speed is faster than RDD.\n",
    "- Of course, this speed is only reflected in structured data. We know that dataframe is structured data. But RDD can also handle semi-structured data items like Mongle DB, json, etc. RDD is more versatile."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FIT5202 Assignment 1 SOLUTION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
